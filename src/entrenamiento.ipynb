{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n",
      "Found 237 images belonging to 7 classes.\n",
      "Found 56 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import shutil\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "\n",
    "data_dir = '../data/dataDDR'\n",
    "dataset_dir = '../data/datasetDDR'\n",
    "\n",
    "##ESCOGER MENOR TAMAÑO DE CARPETA\n",
    "\n",
    "folders = [folder for folder in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, folder))]\n",
    "tamanos =[]\n",
    "for folder in folders:\n",
    "    folder_path = os.path.join(data_dir, folder)\n",
    "    file_count = len(os.listdir(folder_path))\n",
    "    tamanos.append(file_count)\n",
    "\n",
    "menor = min(tamanos)\n",
    "print(menor)\n",
    "\n",
    "##LIMITAR A MENOR TAMAÑO DE CARPETA\n",
    "carpeta_fuente = data_dir\n",
    "carpeta_destino = dataset_dir\n",
    "\n",
    "carpetas = os.listdir(carpeta_fuente)\n",
    "\n",
    "for carpeta in carpetas:\n",
    "    if not carpeta.startswith(\".\"):\n",
    "        imagenes = os.listdir(carpeta_fuente + '/' + carpeta)\n",
    "\n",
    "        for i, nombreimg in enumerate(imagenes):\n",
    "            if i < 42:\n",
    "                if not nombreimg.startswith(\".\"):\n",
    "                    shutil.copy(carpeta_fuente + '/' + carpeta + '/' + nombreimg, carpeta_destino + '/' + carpeta + '/' + nombreimg)\n",
    "\n",
    "##CREAR GENERADORES DE IMAGENES CON DATA AUGMENTATION\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    rotation_range = 30,\n",
    "    width_shift_range = 0.10,\n",
    "    height_shift_range = 0.10,\n",
    "    zoom_range = [0.5, 1.5],\n",
    "    validation_split=0.2 #20% para pruebas\n",
    ")\n",
    "\n",
    "##GENERADORES PARA ENTRENAMIENTO Y PRUEBAS\n",
    "data_gen_entrenamiento = datagen.flow_from_directory(dataset_dir, target_size=(224,224),\n",
    "                                                     batch_size=32, shuffle=True, subset='training')\n",
    "data_gen_pruebas = datagen.flow_from_directory(dataset_dir, target_size=(224,224),\n",
    "                                                     batch_size=32, shuffle=True, subset='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\super\\OneDrive - UNIVERSIDAD DE SEVILLA\\TFG\\workspace\\venv\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\super\\OneDrive - UNIVERSIDAD DE SEVILLA\\TFG\\workspace\\venv\\Lib\\site-packages\\tensorflow_estimator\\python\\estimator\\util.py:74: The name tf.train.SessionRunHook is deprecated. Please use tf.estimator.SessionRunHook instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\super\\OneDrive - UNIVERSIDAD DE SEVILLA\\TFG\\workspace\\venv\\Lib\\site-packages\\tensorflow_hub\\native_module.py:92: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\super\\OneDrive - UNIVERSIDAD DE SEVILLA\\TFG\\workspace\\venv\\Lib\\site-packages\\tensorflow_hub\\saved_model_module.py:40: The name tf.saved_model.constants.LEGACY_INIT_OP_KEY is deprecated. Please use tf.compat.v1.saved_model.constants.LEGACY_INIT_OP_KEY instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\super\\OneDrive - UNIVERSIDAD DE SEVILLA\\TFG\\workspace\\venv\\Lib\\site-packages\\tensorflow_hub\\resolver.py:120: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\super\\OneDrive - UNIVERSIDAD DE SEVILLA\\TFG\\workspace\\venv\\Lib\\site-packages\\tensorflow_hub\\resolver.py:120: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\super\\OneDrive - UNIVERSIDAD DE SEVILLA\\TFG\\workspace\\venv\\Lib\\site-packages\\tensorflow_hub\\module_v2.py:120: The name tf.saved_model.load_v2 is deprecated. Please use tf.compat.v2.saved_model.load instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\super\\OneDrive - UNIVERSIDAD DE SEVILLA\\TFG\\workspace\\venv\\Lib\\site-packages\\tensorflow_hub\\module_v2.py:120: The name tf.saved_model.load_v2 is deprecated. Please use tf.compat.v2.saved_model.load instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\super\\OneDrive - UNIVERSIDAD DE SEVILLA\\TFG\\workspace\\venv\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\super\\OneDrive - UNIVERSIDAD DE SEVILLA\\TFG\\workspace\\venv\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "url = \"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\"\n",
    "mobilenetv2 = hub.KerasLayer(url, input_shape=(224,224,3))\n",
    "\n",
    "#Congelar el modelo descargado\n",
    "mobilenetv2.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " keras_layer (KerasLayer)    (None, 1280)              2257984   \n",
      "                                                                 \n",
      " dense (Dense)               (None, 7)                 8967      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2266951 (8.65 MB)\n",
      "Trainable params: 8967 (35.03 KB)\n",
      "Non-trainable params: 2257984 (8.61 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelo = tf.keras.Sequential([\n",
    "    mobilenetv2,\n",
    "    tf.keras.layers.Dense(7, activation='softmax')\n",
    "])\n",
    "modelo.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'(' was never closed (3378427090.py, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[5], line 5\u001b[1;36m\u001b[0m\n\u001b[1;33m    modelo.compile(\u001b[0m\n\u001b[1;37m                  ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m '(' was never closed\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "#Compilar como siempre\n",
    "modelo.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spicy\n",
    "\n",
    "#Entrenar el modelo\n",
    "EPOCAS = 50\n",
    "\n",
    "historial = modelo.fit(\n",
    "    data_gen_entrenamiento, epochs=EPOCAS, batch_size=32,\n",
    "    validation_data=data_gen_pruebas\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import save_model\n",
    "\n",
    "save_model(modelo, './models/modeloDDR.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Graficas de precisión\n",
    "acc = historial.history['accuracy']\n",
    "val_acc = historial.history['val_accuracy']\n",
    "\n",
    "loss = historial.history['loss']\n",
    "val_loss = historial.history['val_loss']\n",
    "\n",
    "rango_epocas = range(50)\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(rango_epocas, acc, label='Precisión Entrenamiento')\n",
    "plt.plot(rango_epocas, val_acc, label='Precisión Pruebas')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Precisión de entrenamiento y pruebas')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(rango_epocas, loss, label='Pérdida de entrenamiento')\n",
    "plt.plot(rango_epocas, val_loss, label='Pérdida de pruebas')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Pérdida de entrenamiento y pruebas')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "custom_objects = {'KerasLayer': hub.KerasLayer}\n",
    "modelo = load_model('modelo.h5', custom_objects=custom_objects)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
