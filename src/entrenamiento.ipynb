{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import shutil\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import spicy\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.models import save_model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "\n",
    "\n",
    "\n",
    "key_day = \"LS\"\n",
    "data_dir = f'../data/data{key_day}'\n",
    "dataset_dir = f'../data/dataset{key_day}'\n",
    "\n",
    "##ESCOGER MENOR TAMAÑO DE CARPETA\n",
    "\n",
    "folders = [folder for folder in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, folder))]\n",
    "num_hermandades = len(folders)\n",
    "tamanos =[]\n",
    "for folder in folders:\n",
    "    folder_path = os.path.join(data_dir, folder)\n",
    "    file_count = len(os.listdir(folder_path))\n",
    "    tamanos.append(file_count)\n",
    "\n",
    "menor = min(tamanos)\n",
    "print(menor)\n",
    "\n",
    "##LIMITAR A MENOR TAMAÑO DE CARPETA\n",
    "carpeta_fuente = data_dir\n",
    "carpeta_destino = dataset_dir\n",
    "\n",
    "carpetas = os.listdir(carpeta_fuente)\n",
    "\n",
    "for carpeta in carpetas:\n",
    "    if not carpeta.startswith(\".\"):\n",
    "        imagenes = os.listdir(carpeta_fuente + '/' + carpeta)\n",
    "\n",
    "        for i, nombreimg in enumerate(imagenes):\n",
    "            if i < 42:\n",
    "                if not nombreimg.startswith(\".\"):\n",
    "                    shutil.copy(carpeta_fuente + '/' + carpeta + '/' + nombreimg, carpeta_destino + '/' + carpeta + '/' + nombreimg)\n",
    "\n",
    "##CREAR GENERADORES DE IMAGENES CON DATA AUGMENTATION\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    rotation_range = 30,\n",
    "    zoom_range = [0.5, 1.5],\n",
    "    validation_split=0.2 #20% para pruebas\n",
    ")\n",
    "\n",
    "##GENERADORES PARA ENTRENAMIENTO Y PRUEBAS\n",
    "data_gen_entrenamiento = datagen.flow_from_directory(dataset_dir, target_size=(224,224),\n",
    "                                                     batch_size=32, shuffle=True, subset='training')\n",
    "data_gen_pruebas = datagen.flow_from_directory(dataset_dir, target_size=(224,224),\n",
    "                                                     batch_size=32, shuffle=True, subset='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MODELO MOBILENET APP\n",
    "\n",
    "mobilenetAPP = tf.keras.applications.MobileNetV2(input_shape=(224,224,3), include_top=False, weights='imagenet')\n",
    "mobilenetAPP.trainable = False\n",
    "\n",
    "modelo_mobilenetAPP = tf.keras.Sequential([\n",
    "    mobilenetAPP,\n",
    "    tf.keras.layers.GlobalAveragePooling2D(),\n",
    "    tf.keras.layers.Dense(num_hermandades, activation='softmax')\n",
    "])\n",
    " \n",
    "modelo_mobilenetAPP.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "EPOCAS = 100\n",
    "\n",
    "historialMNAPP = modelo_mobilenetAPP.fit(\n",
    "    data_gen_entrenamiento, epochs=EPOCAS, batch_size=32,\n",
    "    validation_data=data_gen_pruebas\n",
    ")\n",
    "\n",
    "save_model(modelo_mobilenetAPP, f'../models/{key_day}/{key_day}MOBILENETV2{EPOCAS}.h5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MODELO RESNETV2 APP - SOBREAJUSTE\n",
    "\n",
    "from tensorflow.keras.applications import ResNet50V2\n",
    "\n",
    "base_model = ResNet50V2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "modelo_resnet = tf.keras.Sequential([\n",
    "    base_model,\n",
    "    tf.keras.layers.GlobalAveragePooling2D(),\n",
    "    tf.keras.layers.Dense(num_hermandades, activation='softmax')\n",
    "])\n",
    "\n",
    "modelo_resnet.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "EPOCAS = 30\n",
    "\n",
    "historialRS = modelo_resnet.fit(\n",
    "    data_gen_entrenamiento, epochs=EPOCAS, batch_size=32,\n",
    "    validation_data=data_gen_pruebas\n",
    ")\n",
    "\n",
    "save_model(modelo_resnet, f'../models/{key_day}/{key_day}RESNET{EPOCAS}.h5')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MODELO EFFICENTNET APP - SOBREAJUSTE \n",
    "\n",
    "from tensorflow.keras.applications import EfficientNetV2B0\n",
    "\n",
    "efficent = EfficientNetV2B0(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "efficent.trainable = False\n",
    "\n",
    "modelo_efficent = tf.keras.Sequential([\n",
    "    efficent,\n",
    "    tf.keras.layers.GlobalAveragePooling2D(),\n",
    "    tf.keras.layers.Dense(num_hermandades, activation='softmax')\n",
    "])\n",
    "\n",
    "modelo_efficent.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "EPOCAS = 100\n",
    "\n",
    "historialE = modelo_efficent.fit(\n",
    "    data_gen_entrenamiento, epochs=EPOCAS, batch_size=32,\n",
    "    validation_data=data_gen_pruebas\n",
    ")\n",
    "\n",
    "save_model(modelo_efficent, f'../models/{key_day}/{key_day}EFFICENT{EPOCAS}.h5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import DenseNet121\n",
    "\n",
    "densenet = DenseNet121(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "densenet.trainable = False\n",
    "\n",
    "modelo_densenet = tf.keras.Sequential([\n",
    "    densenet,\n",
    "    tf.keras.layers.GlobalAveragePooling2D(),\n",
    "    tf.keras.layers.Dense(num_hermandades, activation='softmax')\n",
    "])\n",
    "\n",
    "modelo_densenet.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "EPOCAS = 100\n",
    "\n",
    "historialDN = modelo_densenet.fit(\n",
    "    data_gen_entrenamiento, epochs=EPOCAS, batch_size=32,\n",
    "    validation_data=data_gen_pruebas\n",
    ")\n",
    "\n",
    "save_model(modelo_densenet, f'../models/{key_day}/{key_day}DENSENET{EPOCAS}.h5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import InceptionV3\n",
    "\n",
    "inception = InceptionV3(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "inception.trainable = False\n",
    "\n",
    "modelo_inception = tf.keras.Sequential([\n",
    "    inception,\n",
    "    tf.keras.layers.GlobalAveragePooling2D(),\n",
    "    tf.keras.layers.Dense(num_hermandades, activation='softmax')\n",
    "])\n",
    "\n",
    "modelo_inception.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "EPOCAS = 100\n",
    "\n",
    "historial_inception = modelo_inception.fit(\n",
    "    data_gen_entrenamiento, epochs=EPOCAS, batch_size=32,\n",
    "    validation_data=data_gen_pruebas\n",
    ")\n",
    "\n",
    "save_model(modelo_inception, f'../models/{key_day}/{key_day}INCEPTION{EPOCAS}.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import NASNetMobile\n",
    "\n",
    "nasnet = NASNetMobile(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "nasnet.trainable = False\n",
    "\n",
    "modelo_nasnet = tf.keras.Sequential([\n",
    "    nasnet,\n",
    "    tf.keras.layers.GlobalAveragePooling2D(),\n",
    "    tf.keras.layers.Dense(num_hermandades, activation='softmax')\n",
    "])\n",
    "\n",
    "modelo_nasnet.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "EPOCAS = 100\n",
    "\n",
    "historial_nasnet = modelo_nasnet.fit(\n",
    "    data_gen_entrenamiento, epochs=EPOCAS, batch_size=32,\n",
    "    validation_data=data_gen_pruebas\n",
    ")\n",
    "\n",
    "save_model(modelo_nasnet, f'../models/{key_day}/{key_day}NASNET{EPOCAS}.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NASNET CON MEJORAS\n",
    "from tensorflow.keras.applications import NASNetMobile\n",
    "\n",
    "nasnet = NASNetMobile(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "nasnet.trainable = False\n",
    "\n",
    "modelo_nasnet = tf.keras.Sequential([\n",
    "    nasnet,\n",
    "    tf.keras.layers.GlobalAveragePooling2D(),\n",
    "    tf.keras.layers.Dense(num_hermandades, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "modelo_nasnet.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "EPOCAS = 30\n",
    "\n",
    "historial_nasnet = modelo_nasnet.fit(\n",
    "    data_gen_entrenamiento, epochs=EPOCAS, batch_size=32,\n",
    "    validation_data=data_gen_pruebas\n",
    ")\n",
    "\n",
    "save_model(modelo_nasnet, f'../models/{key_day}/{key_day}NASNETPLUS{EPOCAS}.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Graficas de precisión\n",
    "\n",
    "historial = historial_nasnet\n",
    "acc = historial.history['accuracy']\n",
    "val_acc = historial.history['val_accuracy']\n",
    "\n",
    "loss = historial.history['loss']\n",
    "val_loss = historial.history['val_loss']\n",
    "\n",
    "rango_epocas = range(EPOCAS)\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(rango_epocas, acc, label='Precisión Entrenamiento')\n",
    "plt.plot(rango_epocas, val_acc, label='Precisión Pruebas')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Precisión de entrenamiento y pruebas')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(rango_epocas, loss, label='Pérdida de entrenamiento')\n",
    "plt.plot(rango_epocas, val_loss, label='Pérdida de pruebas')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Pérdida de entrenamiento y pruebas')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
