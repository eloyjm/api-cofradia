{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n",
      "Found 237 images belonging to 7 classes.\n",
      "Found 56 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import shutil\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import spicy\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.models import save_model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "\n",
    "\n",
    "\n",
    "key_day = \"DDR\"\n",
    "data_dir = f'../data/data{key_day}'\n",
    "dataset_dir = f'../data/dataset{key_day}'\n",
    "\n",
    "##ESCOGER MENOR TAMAÑO DE CARPETA\n",
    "\n",
    "folders = [folder for folder in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, folder))]\n",
    "num_hermandades = len(folders)\n",
    "tamanos =[]\n",
    "for folder in folders:\n",
    "    folder_path = os.path.join(data_dir, folder)\n",
    "    file_count = len(os.listdir(folder_path))\n",
    "    tamanos.append(file_count)\n",
    "\n",
    "menor = min(tamanos)\n",
    "print(menor)\n",
    "\n",
    "##LIMITAR A MENOR TAMAÑO DE CARPETA\n",
    "carpeta_fuente = data_dir\n",
    "carpeta_destino = dataset_dir\n",
    "\n",
    "carpetas = os.listdir(carpeta_fuente)\n",
    "\n",
    "for carpeta in carpetas:\n",
    "    if not carpeta.startswith(\".\"):\n",
    "        imagenes = os.listdir(carpeta_fuente + '/' + carpeta)\n",
    "\n",
    "        for i, nombreimg in enumerate(imagenes):\n",
    "            if i < 42:\n",
    "                if not nombreimg.startswith(\".\"):\n",
    "                    shutil.copy(carpeta_fuente + '/' + carpeta + '/' + nombreimg, carpeta_destino + '/' + carpeta + '/' + nombreimg)\n",
    "\n",
    "##CREAR GENERADORES DE IMAGENES CON DATA AUGMENTATION\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    rotation_range = 30,\n",
    "    zoom_range = [0.5, 1.5],\n",
    "    validation_split=0.2 #20% para pruebas\n",
    ")\n",
    "\n",
    "##GENERADORES PARA ENTRENAMIENTO Y PRUEBAS\n",
    "data_gen_entrenamiento = datagen.flow_from_directory(dataset_dir, target_size=(224,224),\n",
    "                                                     batch_size=32, shuffle=True, subset='training')\n",
    "data_gen_pruebas = datagen.flow_from_directory(dataset_dir, target_size=(224,224),\n",
    "                                                     batch_size=32, shuffle=True, subset='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\super\\OneDrive - UNIVERSIDAD DE SEVILLA\\TFG\\workspace\\cofradIA\\venv\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\super\\OneDrive - UNIVERSIDAD DE SEVILLA\\TFG\\workspace\\cofradIA\\venv\\Lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "A `Concatenate` layer requires inputs with matching shapes except for the concatenation axis. Received: input_shape=[(None, 5, 5, 2048), (None, 1)]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m inception_output \u001b[38;5;241m=\u001b[39m inception(input_imagen)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Concatenar la salida de InceptionV3 con la entrada del día de la semana\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m concatenated_output \u001b[38;5;241m=\u001b[39m \u001b[43mConcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43minception_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_dia_semana\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Capa de pooling global y capa densa final\u001b[39;00m\n\u001b[0;32m     22\u001b[0m global_avg_pooling \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mGlobalAveragePooling2D()(concatenated_output)\n",
      "File \u001b[1;32mc:\\Users\\super\\OneDrive - UNIVERSIDAD DE SEVILLA\\TFG\\workspace\\cofradIA\\venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\super\\OneDrive - UNIVERSIDAD DE SEVILLA\\TFG\\workspace\\cofradIA\\venv\\Lib\\site-packages\\keras\\src\\layers\\merging\\concatenate.py:119\u001b[0m, in \u001b[0;36mConcatenate.build\u001b[1;34m(self, input_shape)\u001b[0m\n\u001b[0;32m    117\u001b[0m ranks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mlen\u001b[39m(shape) \u001b[38;5;28;01mfor\u001b[39;00m shape \u001b[38;5;129;01min\u001b[39;00m shape_set)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(ranks) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 119\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(err_msg)\n\u001b[0;32m    120\u001b[0m \u001b[38;5;66;03m# Get the only rank for the set.\u001b[39;00m\n\u001b[0;32m    121\u001b[0m (rank,) \u001b[38;5;241m=\u001b[39m ranks\n",
      "\u001b[1;31mValueError\u001b[0m: A `Concatenate` layer requires inputs with matching shapes except for the concatenation axis. Received: input_shape=[(None, 5, 5, 2048), (None, 1)]"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras.layers import Input, Concatenate, GlobalAveragePooling2D\n",
    "\n",
    "input_imagen = Input(shape=(224, 224, 3), name='input_imagen')\n",
    "\n",
    "# Entrada para el día de la semana\n",
    "input_dia_semana = Input(shape=(1,), name='input_dia_semana')\n",
    "\n",
    "# Cargar el modelo InceptionV3\n",
    "inception = InceptionV3(weights='imagenet', include_top=False, input_tensor=input_imagen)\n",
    "inception.trainable = False\n",
    "\n",
    "# Salida del modelo InceptionV3\n",
    "inception_output = inception(input_imagen)\n",
    "\n",
    "# Global Average Pooling en la salida del modelo InceptionV3\n",
    "global_avg_pooling_inception = GlobalAveragePooling2D()(inception_output)\n",
    "\n",
    "# Concatenar la salida de InceptionV3 con la entrada del día de la semana\n",
    "concatenated_output = Concatenate()([global_avg_pooling_inception, input_dia_semana])\n",
    "\n",
    "# Capa densa para procesar la información combinada\n",
    "dense_combined = Dense(512, activation='relu')(concatenated_output)\n",
    "\n",
    "# Capa de salida para la clasificación final\n",
    "output_layer = Dense(num_hermandades, activation='softmax')(dense_combined)\n",
    "\n",
    "# Crear el modelo final\n",
    "modelo_final = tf.keras.Model(inputs=[input_imagen, input_dia_semana], outputs=output_layer)\n",
    "\n",
    "# Compilar el modelo\n",
    "modelo_final.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "EPOCAS = 20\n",
    "data_dia = np.array([[0]])\n",
    "\n",
    "\n",
    "'''\n",
    "# Continuar entrenando el modelo con datos de MARTES\n",
    "historial_inception_martes = modelo_inception.fit(\n",
    "    {'input_imagen': data_gen_entrenamiento, 'input_dia_semana': key_day},\n",
    "    epochs=EPOCAS,\n",
    "    batch_size=32,\n",
    "    validation_data=(\n",
    "        {'input_imagen': data_gen_pruebas, 'input_dia_semana': key_day},\n",
    "        data_gen_pruebas[1]\n",
    "    )\n",
    ")\n",
    "\n",
    "# Guardar el modelo entrenado con datos de MARTES\n",
    "save_model(modelo_inception, f'../models/{key_day}/{key_day}INCEPTION{EPOCAS}_MARTES.h5')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar el modelo final con datos de entrenamiento\n",
    "historial_modelo_final = modelo_final.fit(\n",
    "    {'input_imagen': data_gen_entrenamiento, 'input_dia_semana': data_dia},\n",
    "    epochs=EPOCAS,\n",
    "    batch_size=32,\n",
    "    validation_data=(\n",
    "        {'input_imagen': data_gen_pruebas, 'input_dia_semana': data_dia},\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar el modelo con datos de LUNES\n",
    "historial_inception_lunes = modelo_inception.fit(\n",
    "    {'input_imagen': data_gen_entrenamiento, 'input_dia_semana': data_dia},\n",
    "    epochs=EPOCAS,\n",
    "    batch_size=32,\n",
    "    validation_data=(\n",
    "        {'input_imagen': data_gen_pruebas, 'input_dia_semana': data_dia}\n",
    "    )\n",
    ")\n",
    "\n",
    "# Guardar el modelo entrenado con datos de LUNES\n",
    "save_model(modelo_inception, f'../models/FULLINCEPTION{EPOCAS}_LUNES.h5')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
